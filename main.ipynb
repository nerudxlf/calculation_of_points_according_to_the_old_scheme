{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPQIkiJIVqtRznrQAQ+2KLR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nerudxlf/calculation_of_points_according_to_the_old_scheme/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kmHEz9QjXYX"
      },
      "source": [
        "import re\r\n",
        "import pandas as pd\r\n",
        "from google.colab import files\r\n",
        "\r\n",
        "files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHfI5ATVjduG"
      },
      "source": [
        "def rename_and_filter_df(data: object) -> object:\r\n",
        "  data.rename(\r\n",
        "    columns={\"Source Title_x\": \"Source Title\", \"Title_x\": \"Title\", \"Affiliations_x\": \"Affiliations\"}, inplace=True)\r\n",
        "  return data.filter([\"Source Title\", \"Title\", \"Affiliations\", \"KEY\"])\r\n",
        "\r\n",
        "\r\n",
        "def filter_data_wos(data: object) -> object:\r\n",
        "  data = data.filter([\"Full Journal Title\", \"Article Title\", \"Addresses\"])\r\n",
        "  data.rename(columns={\"Full Journal Title\": \"Source Title\", \"Article Title\": \"Title\", \"Addresses\": \"Affiliations\"},\r\n",
        "              inplace=True)\r\n",
        "  title_list = data[\"Title\"].to_list()\r\n",
        "  key_list = []\r\n",
        "  for item in title_list:\r\n",
        "    reg = re.sub(r'[^A-Za-z0-9]', '', item)\r\n",
        "    key_list.append(reg.upper())\r\n",
        "  data[\"KEY\"] = key_list\r\n",
        "  return data\r\n",
        "\r\n",
        "\r\n",
        "def filter_data_scopus(data: object) -> object:\r\n",
        "  data = data.filter([\"Source Title\", \"Title\", \"Authors with affiliations\"])\r\n",
        "  data.rename(columns={\"Authors with affiliations\": \"Affiliations\"}, inplace=True)\r\n",
        "  title_list = data[\"Title\"].to_list()\r\n",
        "  key_list = []\r\n",
        "  for item in title_list:\r\n",
        "    reg = re.sub(r'[^A-Za-z0-9]', '', item)\r\n",
        "    key_list.append(reg.upper())\r\n",
        "  data[\"KEY\"] = key_list\r\n",
        "  return data\r\n",
        "\r\n",
        "\r\n",
        "def get_result(all_data: object, w_data: object, num: int, file_name: str, total: int) -> (int, object):\r\n",
        "  data_result = pd.merge(left=all_data, right=w_data, left_on=\"KEY\", right_on=\"KEY\")\r\n",
        "  data_result = rename_and_filter_df(data_result)\r\n",
        "  total += len(data_result.index) * num\r\n",
        "  data_result.to_excel(file_name, index=False)\r\n",
        "  all_data_minus = pd.concat([data_result, all_data])\r\n",
        "  all_data_minus.drop_duplicates(keep=False, inplace=True)\r\n",
        "  return total, all_data_minus\r\n",
        "\r\n",
        "\r\n",
        "def get_result_50(all_data: object, w_data: object, s_data: object, num: int, file_name: str,\r\n",
        "                  total: int) -> (int, object):\r\n",
        "  data_result = pd.merge(left=all_data, right=w_data, left_on=\"KEY\", right_on=\"KEY\")\r\n",
        "  data_result = rename_and_filter_df(data_result)\r\n",
        "  total += len(data_result.index) * num\r\n",
        "  all_data_minus_w = pd.concat([data_result, all_data])\r\n",
        "  all_data_minus_w.drop_duplicates(keep=False, inplace=True)\r\n",
        "  w_and_s_data_result = pd.merge(left=all_data_minus_w, right=s_data, left_on=\"KEY\", right_on=\"KEY\")\r\n",
        "  w_and_s_data_result = rename_and_filter_df(w_and_s_data_result)\r\n",
        "  total += len(w_and_s_data_result.index) * num\r\n",
        "  w_and_s_data_result.to_excel(file_name, index=False)\r\n",
        "  all_data_minus_w_and_s = pd.concat([w_and_s_data_result, all_data_minus_w])\r\n",
        "  all_data_minus_w_and_s.drop_duplicates(keep=False, inplace=True)\r\n",
        "  return total, all_data_minus_w_and_s"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGJI6EoKj1o9"
      },
      "source": [
        "total: int = 0\r\n",
        "s1_data = filter_data_scopus(pd.read_excel(\"s1.xlsx\"))\r\n",
        "s2_data = filter_data_scopus(pd.read_excel(\"s2.xlsx\"))\r\n",
        "s3_data = filter_data_scopus(pd.read_excel(\"s3.xlsx\"))\r\n",
        "s4_data = filter_data_scopus(pd.read_excel(\"s4.xlsx\"))\r\n",
        "s_none_data = filter_data_scopus(pd.read_excel(\"s_none.xlsx\"))\r\n",
        "w1_data = filter_data_wos(pd.read_excel(\"w1.xlsx\"))\r\n",
        "w2_data = filter_data_wos(pd.read_excel(\"w2.xlsx\"))\r\n",
        "w3_data = filter_data_wos(pd.read_excel(\"w3.xlsx\"))\r\n",
        "w4_data = filter_data_wos(pd.read_excel(\"w4.xlsx\"))\r\n",
        "w_none_data = filter_data_wos(pd.read_excel(\"w_none.xlsx\"))\r\n",
        "\r\n",
        "all_data = pd.concat(\r\n",
        "  [s1_data, s2_data, s3_data, s4_data, s_none_data, w1_data, w2_data, w3_data, w4_data, w_none_data])\r\n",
        "all_data = all_data.drop_duplicates(subset=[\"KEY\"])\r\n",
        "\r\n",
        "total, all_data = get_result(all_data, w1_data, 70, \"70.xlsx\", total)\r\n",
        "print(f\"w1 - {total} all len - {len(all_data.index)}\")\r\n",
        "\r\n",
        "total, all_data = get_result_50(all_data, w2_data, s1_data, 50, \"50.xlsx\", total)\r\n",
        "print(f\"w2 and s1 - {total} all len - {len(all_data.index)}\")\r\n",
        "\r\n",
        "total, all_data = get_result(all_data, s2_data, 30, \"30.xlsx\", total)\r\n",
        "print(f\"s2 - {total} all len - {len(all_data.index)}\")\r\n",
        "\r\n",
        "total, all_data = get_result(all_data, w3_data, 25, \"25.xlsx\", total)\r\n",
        "print(f\"w3 - {total} all len - {len(all_data.index)}\")\r\n",
        "\r\n",
        "total, all_data = get_result(all_data, w4_data, 18, \"18.xlsx\", total)\r\n",
        "print(f\"w4 - {total} all len - {len(all_data.index)}\")\r\n",
        "\r\n",
        "total, all_data = get_result(all_data, s3_data, 15, \"15.xlsx\", total)\r\n",
        "print(f\"s3 - {total} all len - {len(all_data.index)}\")\r\n",
        "\r\n",
        "total, all_data = get_result(all_data, s4_data, 9, \"9.xlsx\", total)\r\n",
        "print(f\"s4 - {total} all len - {len(all_data.index)}\")\r\n",
        "\r\n",
        "all_data_minus_s4 = all_data.drop_duplicates(subset=[\"KEY\"])\r\n",
        "total += len(all_data_minus_s4.index) * 7\r\n",
        "print(f\"all - {total} all len - {len(all_data_minus_s4.index)}\")\r\n",
        "all_data_minus_s4.to_excel(\"7.xlsx\", index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}